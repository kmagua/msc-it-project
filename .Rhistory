#prop.table(table(credit_test$default))
library(C50)
credit <- read.csv('decision_tree/credit.csv')
#1 exlore data
#str(credit)
#summary(credit$age)
#table(credit$default)
#table(credit$checking_balance)
#table(credit$savings_balance)
# Randomize train/test data select
set.seed(123)
train_sample <- sample(1000, 900)
credit_train <- credit[train_sample,]
credit_test <- credit[-train_sample,]
#prop.table(table(credit_train$default)) #### should be about 30% each for defaulters
#prop.table(table(credit_test$default))
library(C50)
data(credit)
table(credit$default)
credit_model <- C5.0(credit_train[-17], credit_train$default)
credit_model
#credit_model tree details
summary(credit_model)
library(MASS)
data("Pima.tr")
mushrooms <- read.csv("decision_tree/rules/mushrooms.csv", stringsAsFactors = TRUE)
str(mushrooms)
mushrooms$veil_type <- NULL #remove this as all the values are the same
str(mushrooms)
table(mushrooms$type)
library(RWeka)
install.packages('RWeka')
library(RWeka)
install.packages('RWeka')
library(RWeka)
library(RWeka)
library(RWeka)
mushroom_1R <- OneR(type ~ ., data = mushrooms)
mushroom_1R
summary(mushroom_1R)
#improving performance
#using a more sophisticated rule learner
mushroom_JRip <- JRip(type ~ ., data = mushrooms)
mushroom_JRip
launch <- read.csv("lr/challenger.csv")
r <- cov(launch$temperature, launch$distress_ct) / (sd(launch$temperature) * sd(launch$distress_ct))
r
reg <- function(y, x) {
x <- as.matrix(x)
x <- cbind(Intercept = 1, x)
b <- solve(t(x) %*% x) %*% t(x) %*% y
colnames(b) <- "estimate"
print(b)
}
str(launch)
reg(y = launch$distress_ct, x = launch[2])
reg(y = launch$distress_ct, x = launch[2:4])
#  XXXXXXXXXXX Example - Example – predicting medical expenses using linear regression XXXXXXXXXXXXXX
insurance <- read.csv("lr/insurance.csv", stringsAsFactors = TRUE)
str(insurance)
summary(insurance$expenses)
insurance <- read.csv("lr/insurance.csv", stringsAsFactors = TRUE)
summary(insurance$expenses)
str(insurance)
summary(insurance$charges)
hist(insurance$charges)
table(insurance$region)
#explore data -  Correlation Matrix
cor(insurance[c("age", "bmi", "children", "expenses")])
#explore data -  Correlation Matrix
cor(insurance[c("age", "bmi", "children", "charges")])
#scatter plot for pairs
pairs(insurance[c("age", "bmi", "children", "expenses")])
#scatter plot for pairs
pairs(insurance[c("age", "bmi", "children", "charges")])
install.packages("psych")
#Training a model
ins_model <- lm(expenses ~ age + children + bmi + sex + smoker + region, data = insurance)
#launch <- read.csv("lr/challenger.csv")
#r <- cov(launch$temperature, launch$distress_ct) / (sd(launch$temperature) * sd(launch$distress_ct))
#reg <- function(y, x) {
#    x <- as.matrix(x)
#    x <- cbind(Intercept = 1, x)
#    b <- solve(t(x) %*% x) %*% t(x) %*% y
#    colnames(b) <- "estimate"
#    print(b)
#}
## Simple LR
#reg(y = launch$distress_ct, x = launch[2])
##multiple LR
#reg(y = launch$distress_ct, x = launch[2:4])
#  XXXXXXXXXXX Example - Example – predicting medical expenses using linear regression XXXXXXXXXXXXXX
insurance <- read.csv("lr/insurance.csv", stringsAsFactors = TRUE)
#explore data -  Correlation Matrix
cor(insurance[c("age", "bmi", "children", "charges")])
#scatter plot for pairs
pairs(insurance[c("age", "bmi", "children", "charges")])
#Training a model
ins_model <- lm(expenses ~ age + children + bmi + sex + smoker + region, data = insurance)
# ins_model <- lm(expenses ~ ., data = insurance) ##### similar to above
#Training a model
ins_model <- lm(charges ~ age + children + bmi + sex + smoker + region, data = insurance)
ins_model
summary(ins_model)
# ins_model <- lm(charges ~ ., data = insurance) ##### similar to above
#view model performance
summary(ins_model)
## XXXXXXXXXXXXX improving the model XXXXXXXXXXXXXX
#adding non-linear relationships
insurance$age2 <- insurance$age^2
#transform numeric to binary ### All obese cases to have 1 0 otherwise
insurance$bmi30 <- ifelse(insurance$bmi >= 30, 1, 0)
#Model specification – adding interaction effects #some group of features could have combined effect
#bmi30*smoker
ins_model2 <- lm(charges ~ age + age2 + children + bmi + sex + bmi30*smoker + region, data = insurance)
summary(ins_model2)
wine <- read.csv("lr/whitewines.csv")
#divide the data into train/test
wine_train <- wine[1:3750, ]
wine_test <- wine[3751:4898, ]
library(rpart)
#training a model
m.rpart <- rpart(quality ~ ., data = wine_train)
m.rpart
chd <- read.csv("Project/chronic_kidney_disease_full.csv")
str(chd)
chd[ chd == "?" ] <- NA
str(chd)
chd <- read.csv("Project/chronic_kidney_disease_full.csv", na.strings = c("?", "\t?"))
str(chd)
chd <- read.csv("Project/chronic_kidney_disease_full.csv", na.strings = c("?", "\t?"), stringsAsFactors = TRUE)
str(chd)
ckd <- read.csv("Project/chronic_kidney_disease_full.csv", na.strings = c("?", "\t?"), stringsAsFactors = TRUE)
#chd[ chd == "?" ] <- NA
ckd
ckd <- read.csv("Project/chronic_kidney_disease_full.csv", na.strings = c("?", "\t?"), stringsAsFactors = TRUE)
str(ckd)
ckd <- read.csv("Project/chronic_kidney_disease_full.csv", na.strings = c("?", "\t?"), stringsAsFactors = TRUE)
str(ckd)
ckd <- read.csv("Project/chronic_kidney_disease_full.csv", na.strings = c("?", "\t?"), stringsAsFactors = TRUE)
str(ckd)
ckd <- read.csv("Project/chronic_kidney_disease.csv", na.strings = c("?", "\t?"), stringsAsFactors = TRUE)
str(ckd)
ckd <- read.csv("Project/chronic_kidney_disease.csv", na.strings = c("?", "\t?"), stringsAsFactors = TRUE)
str(ckd)
ckd <- read.csv("Project/chronic_kidney_disease.csv", na.strings = c("?", "\t?"), stringsAsFactors = TRUE)
str(ckd)
#any_na(ckd)
numeric_columns <- unlist(lapply(ckd, is.numeric))
numeric_columns
install.packages('VIM')
install.packages(car)
install.packages('car')
library(VIM)
setwd('Project')
#the Neural Network Package
library(neuralnet)
#boot is used for crossvalidation
#library(caret)
#library(e1071)
#K fold cross validation package
library(modelr)
library(plyr)
#convert missing value character to R's Missing value keyword
ckd <- read.csv("chronic_kidney_disease.csv", na.strings = c("?", "\t?"), stringsAsFactors = TRUE)
#write back the tranformed data into a separate csv
write.csv(ckd, file = "ckd_data_converted.csv",row.names=FALSE, na="")
#write complete cases to a new CSV file
no_missing <- na.omit(ckd)
write.csv(no_missing, file = "original_complete_cases.csv",row.names=FALSE)
# read complete cases file
ckd <- read.csv("original_complete_cases.csv", stringsAsFactors = TRUE)
#Scale numeric attributes
numeric_cols <- sapply(ckd, is.numeric)
standardize_data <- function(x){ (x - min(x))/(max(x) - min(x)) }
ckd[numeric_cols] <- lapply(ckd[numeric_cols], standardize_data)
#str(ckd)
write.csv(ckd, file = "original_complete_cases_numeric_scaled.csv",row.names=FALSE)
ckd <- read.csv("original_complete_cases_numeric_scaled.csv", stringsAsFactors = TRUE)
#convert factors to numeric by changing them into new columns +0/-1 removes the intercept column from the dataset
converted_to_numeric_column <- model.matrix(~age+bp+sg+al+su+rbc+pc+pcc+ba+bgr+bu+sc+sod+pot+hemo+pcv+wc+rc+htn+dm+cad+appet+pe+ane+class+0, ckd)
head(converted_to_numeric_column)
#save the transformed data to a file
write.csv(converted_to_numeric_column, file = "transformed_data.csv",row.names=FALSE)
data = read.csv('transformed_data.csv')
#find correlation between attributes
correlation <- cor(data$pcnormal, data$classnotckd, use="complete.obs", method="kendall")
#XXXXXXXXXXXXXXXX The CUSTOM MODEL FITTING FUNCTION XXXXXXXXXXXXXXXXXXXXX
columns <- NULL
fit_model <- function(k, folding,f,scene){
for(i in 1:k){
train.data <- as.data.frame(folding$train[[i]])
test.data <- as.data.frame(folding$test[[i]])
n_cols <- ncol(train.data) - 1
table(train.data$classnotckd)
nn <- neuralnet(f, data=train.data, hidden=c(5,4), linear.output = T)
#png(file = paste("./images/fold - ",i , scene , " model.png"))
#print(plot(nn))
#dev.off()
#Test the model
pr.nn <- compute(nn,test.data[,1:n_cols])
#Confusion Matrix & Classification error. Saved as png
prediction <- pr.nn$net.result
classified_prediction <- ifelse(prediction>0.5,'No CKD','CKD')
test_data <- ifelse(test.data$classnotckd == 1, 'No CKD','CKD')
cm <- confusionMatrix(factor(classified_prediction), factor(test_data))
confusion_matrix <- as.table(cm)
png(file = paste("./images/fold - ",i , scene , " confusion matrix.png"))
fourfoldplot(confusion_matrix)
dev.off()
#Save the merged training and test data to a file for current fold
train.data$type <- 'train'
test.data$type <- 'test'
write.csv(rbind(train.data, test.data), file = paste("./10-fold-data/",i , scene , " - fold.csv"),row.names=FALSE)
pbar$step()
}
}
# RANDOMIZE THE DATA
rows <- sample(nrow(data))
data <- data[rows, ]
write.csv(data, file = "randomized_records.csv",row.names=FALSE)
# XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
#               1 st test is with the categorical data converted to binary without scaling
# XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
#randomize data
data < read.csv('randomized_records.csv')
set.seed(769)
#find attribute correlation
res <- cor(data)
write.table(round(res, 2), file='./images/my_data.txt', sep="\t")
attribute_labels <- names(data)
f <- as.formula(paste("classnotckd ~", paste(attribute_labels[!attribute_labels %in% "classnotckd"], collapse = " + ")))
k <- 6
pbar <- create_progress_bar('text')
pbar$init(k)
set.seed(897)
folding <- crossv_kfold(data,k)
confusion_matrix <- NULL
fit_model(k,folding, f, ' - Original Data - ')
# XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
#         FITTING THE MODEL with data whose correlation with the outcome variable >60
# XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
#data prep
data < read.csv('randomized_records.csv')
correlation <- read.csv('attributes_correlation.txt')
features <- correlation[abs(correlation$classnotckd) <=0.6, 1]
features <- as.vector(features)
new_data <- subset(data, select=append(features, 'classnotckd'))
#
attribute_labels <- names(new_data)
f <- as.formula(paste("classnotckd ~", paste(attribute_labels[!attribute_labels %in% "classnotckd"], collapse = " + ")))
k <- 6
pbar <- create_progress_bar('text')
pbar$init(k)
set.seed(897)
folding <- crossv_kfold(new_data,k)
confusion_matrix <- NULL
fit_model(k,folding, f, ' - Correlation less than 60 - ')
#boot is used for crossvalidation
library(caret)
setwd('Project')
#the Neural Network Package
library(neuralnet)
#boot is used for crossvalidation
library(caret)
#library(e1071)
#K fold cross validation package
library(modelr)
library(plyr)
#convert missing value character to R's Missing value keyword
ckd <- read.csv("chronic_kidney_disease.csv", na.strings = c("?", "\t?"), stringsAsFactors = TRUE)
#write back the tranformed data into a separate csv
write.csv(ckd, file = "ckd_data_converted.csv",row.names=FALSE, na="")
#write complete cases to a new CSV file
no_missing <- na.omit(ckd)
write.csv(no_missing, file = "original_complete_cases.csv",row.names=FALSE)
# read complete cases file
ckd <- read.csv("original_complete_cases.csv", stringsAsFactors = TRUE)
#Scale numeric attributes
numeric_cols <- sapply(ckd, is.numeric)
standardize_data <- function(x){ (x - min(x))/(max(x) - min(x)) }
ckd[numeric_cols] <- lapply(ckd[numeric_cols], standardize_data)
#str(ckd)
write.csv(ckd, file = "original_complete_cases_numeric_scaled.csv",row.names=FALSE)
ckd <- read.csv("original_complete_cases_numeric_scaled.csv", stringsAsFactors = TRUE)
#convert factors to numeric by changing them into new columns +0/-1 removes the intercept column from the dataset
converted_to_numeric_column <- model.matrix(~age+bp+sg+al+su+rbc+pc+pcc+ba+bgr+bu+sc+sod+pot+hemo+pcv+wc+rc+htn+dm+cad+appet+pe+ane+class+0, ckd)
head(converted_to_numeric_column)
#save the transformed data to a file
write.csv(converted_to_numeric_column, file = "transformed_data.csv",row.names=FALSE)
data = read.csv('transformed_data.csv')
#find correlation between attributes
correlation <- cor(data$pcnormal, data$classnotckd, use="complete.obs", method="kendall")
#XXXXXXXXXXXXXXXX The CUSTOM MODEL FITTING FUNCTION XXXXXXXXXXXXXXXXXXXXX
columns <- NULL
fit_model <- function(k, folding,f,scene){
for(i in 1:k){
train.data <- as.data.frame(folding$train[[i]])
test.data <- as.data.frame(folding$test[[i]])
n_cols <- ncol(train.data) - 1
table(train.data$classnotckd)
nn <- neuralnet(f, data=train.data, hidden=c(5,4), linear.output = T)
#png(file = paste("./images/fold - ",i , scene , " model.png"))
#print(plot(nn))
#dev.off()
#Test the model
pr.nn <- compute(nn,test.data[,1:n_cols])
#Confusion Matrix & Classification error. Saved as png
prediction <- pr.nn$net.result
classified_prediction <- ifelse(prediction>0.5,'No CKD','CKD')
test_data <- ifelse(test.data$classnotckd == 1, 'No CKD','CKD')
cm <- confusionMatrix(factor(classified_prediction), factor(test_data))
confusion_matrix <- as.table(cm)
png(file = paste("./images/fold - ",i , scene , " confusion matrix.png"))
fourfoldplot(confusion_matrix)
dev.off()
#Save the merged training and test data to a file for current fold
train.data$type <- 'train'
test.data$type <- 'test'
write.csv(rbind(train.data, test.data), file = paste("./10-fold-data/",i , scene , " - fold.csv"),row.names=FALSE)
pbar$step()
}
}
# RANDOMIZE THE DATA
rows <- sample(nrow(data))
data <- data[rows, ]
write.csv(data, file = "randomized_records.csv",row.names=FALSE)
# XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
#               1 st test is with the categorical data converted to binary without scaling
# XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
#randomize data
data < read.csv('randomized_records.csv')
set.seed(769)
#find attribute correlation
res <- cor(data)
write.table(round(res, 2), file='./images/my_data.txt', sep="\t")
attribute_labels <- names(data)
f <- as.formula(paste("classnotckd ~", paste(attribute_labels[!attribute_labels %in% "classnotckd"], collapse = " + ")))
k <- 6
pbar <- create_progress_bar('text')
pbar$init(k)
set.seed(897)
folding <- crossv_kfold(data,k)
confusion_matrix <- NULL
fit_model(k,folding, f, ' - Original Data - ')
# XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
#         FITTING THE MODEL with data whose correlation with the outcome variable >60
# XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
#data prep
data < read.csv('randomized_records.csv')
correlation <- read.csv('attributes_correlation.txt')
features <- correlation[abs(correlation$classnotckd) <=0.6, 1]
features <- as.vector(features)
new_data <- subset(data, select=append(features, 'classnotckd'))
#
attribute_labels <- names(new_data)
f <- as.formula(paste("classnotckd ~", paste(attribute_labels[!attribute_labels %in% "classnotckd"], collapse = " + ")))
k <- 6
pbar <- create_progress_bar('text')
pbar$init(k)
set.seed(897)
folding <- crossv_kfold(new_data,k)
confusion_matrix <- NULL
fit_model(k,folding, f, ' - Correlation less than 60 - ')
dev.list()
setwd('Project')
#the Neural Network Package
library(neuralnet)
#boot is used for crossvalidation
library(caret)
#library(e1071)
#K fold cross validation package
library(modelr)
library(plyr)
#convert missing value character to R's Missing value keyword
ckd <- read.csv("chronic_kidney_disease.csv", na.strings = c("?", "\t?"), stringsAsFactors = TRUE)
#write back the tranformed data into a separate csv
write.csv(ckd, file = "ckd_data_converted.csv",row.names=FALSE, na="")
#write complete cases to a new CSV file
no_missing <- na.omit(ckd)
write.csv(no_missing, file = "original_complete_cases.csv",row.names=FALSE)
# read complete cases file
ckd <- read.csv("original_complete_cases.csv", stringsAsFactors = TRUE)
#Scale numeric attributes
numeric_cols <- sapply(ckd, is.numeric)
standardize_data <- function(x){ (x - min(x))/(max(x) - min(x)) }
ckd[numeric_cols] <- lapply(ckd[numeric_cols], standardize_data)
#str(ckd)
write.csv(ckd, file = "original_complete_cases_numeric_scaled.csv",row.names=FALSE)
ckd <- read.csv("original_complete_cases_numeric_scaled.csv", stringsAsFactors = TRUE)
#convert factors to numeric by changing them into new columns +0/-1 removes the intercept column from the dataset
converted_to_numeric_column <- model.matrix(~age+bp+sg+al+su+rbc+pc+pcc+ba+bgr+bu+sc+sod+pot+hemo+pcv+wc+rc+htn+dm+cad+appet+pe+ane+class+0, ckd)
head(converted_to_numeric_column)
#save the transformed data to a file
write.csv(converted_to_numeric_column, file = "transformed_data.csv",row.names=FALSE)
data = read.csv('transformed_data.csv')
#find correlation between attributes
correlation <- cor(data$pcnormal, data$classnotckd, use="complete.obs", method="kendall")
#XXXXXXXXXXXXXXXX The CUSTOM MODEL FITTING FUNCTION XXXXXXXXXXXXXXXXXXXXX
columns <- NULL
fit_model <- function(k, folding,f,scene){
for(i in 1:k){
train.data <- as.data.frame(folding$train[[i]])
test.data <- as.data.frame(folding$test[[i]])
n_cols <- ncol(train.data) - 1
table(train.data$classnotckd)
nn <- neuralnet(f, data=train.data, hidden=c(5,4), linear.output = T)
png(file = paste("./images/fold - ",i , scene , " model.png"))
print(plot(nn))
dev.off()
#Test the model
pr.nn <- compute(nn,test.data[,1:n_cols])
#Confusion Matrix & Classification error. Saved as png
prediction <- pr.nn$net.result
classified_prediction <- ifelse(prediction>0.5,'No CKD','CKD')
test_data <- ifelse(test.data$classnotckd == 1, 'No CKD','CKD')
cm <- confusionMatrix(factor(classified_prediction), factor(test_data))
confusion_matrix <- as.table(cm)
png(file = paste("./images/fold - ",i , scene , " confusion matrix.png"))
fourfoldplot(confusion_matrix)
dev.off()
#Save the merged training and test data to a file for current fold
train.data$type <- 'train'
test.data$type <- 'test'
write.csv(rbind(train.data, test.data), file = paste("./10-fold-data/",i , scene , " - fold.csv"),row.names=FALSE)
pbar$step()
}
}
# RANDOMIZE THE DATA
rows <- sample(nrow(data))
data <- data[rows, ]
write.csv(data, file = "randomized_records.csv",row.names=FALSE)
# XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
#               1 st test is with the categorical data converted to binary without scaling
# XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
#randomize data
data < read.csv('randomized_records.csv')
set.seed(769)
#find attribute correlation
res <- cor(data)
write.table(round(res, 2), file='./images/my_data.txt', sep="\t")
attribute_labels <- names(data)
f <- as.formula(paste("classnotckd ~", paste(attribute_labels[!attribute_labels %in% "classnotckd"], collapse = " + ")))
k <- 6
pbar <- create_progress_bar('text')
pbar$init(k)
set.seed(897)
folding <- crossv_kfold(data,k)
confusion_matrix <- NULL
fit_model(k,folding, f, ' - Original Data - ')
# XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
#         FITTING THE MODEL with data whose correlation with the outcome variable >60
# XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
#data prep
data < read.csv('randomized_records.csv')
correlation <- read.csv('attributes_correlation.txt')
features <- correlation[abs(correlation$classnotckd) <=0.6, 1]
features <- as.vector(features)
new_data <- subset(data, select=append(features, 'classnotckd'))
#
attribute_labels <- names(new_data)
f <- as.formula(paste("classnotckd ~", paste(attribute_labels[!attribute_labels %in% "classnotckd"], collapse = " + ")))
k <- 6
pbar <- create_progress_bar('text')
pbar$init(k)
set.seed(897)
folding <- crossv_kfold(new_data,k)
confusion_matrix <- NULL
fit_model(k,folding, f, ' - Correlation less than 60 - ')
data < read.csv('randomized_records.csv')
#find attribute correlation
res <- cor(data,method = c("pearson", "kendall", "spearman"))
write.table(round(res, 2), file='./images/my_data_new.txt', sep="\t")
res <- cor(data,method = "kendall")
write.table(round(res, 2), file='./images/my_data_new.txt', sep="\t")
read.csv('ckd_data_converted.csv')
ckd.data <-read.csv('ckd_data_converted.csv')
vis_miss(ckd.data, sort_miss = TRUE)
ckd.data <-read.csv('ckd_data_converted.csv')
vis_miss(ckd.data, sort_miss = TRUE)
#used to visualize missing data
library(visdat)
ckd.data <-read.csv('ckd_data_converted.csv')
vis_miss(ckd.data, sort_miss = TRUE)
library(ggplot2)
vis_miss(ckd.data, sort_miss = TRUE)
library(visdat)
library(ggplot2)
library(dplyr)
ckd.data <-read.csv('ckd_data_converted.csv')
vis_miss(ckd.data, sort_miss = TRUE)
glimpse(ckd.data)
library(naniar)
vis_miss(ckd.data, sort_miss = TRUE)
vis_dat(ckd.data)
#convert missing value character to R's Missing value keyword
ckd <- read.csv("chronic_kidney_disease.csv", na.strings = c("?", "\t?"), stringsAsFactors = TRUE)
#write back the tranformed data into a separate csv
write.csv(ckd, file = "ckd_data_converted.csv",row.names=FALSE, na="NA")
ckd.data <-read.csv('ckd_data_converted.csv')
vis_miss(ckd.data, sort_miss = TRUE)
ckd <- read.csv("chronic_kidney_disease.csv", na.strings = c("?", "\t?", ""), stringsAsFactors = TRUE)
#write back the tranformed data into a separate csv
write.csv(ckd, file = "ckd_data_converted.csv",row.names=FALSE, na="NA")
library(visdat)
library(ggplot2)
library(dplyr)
library(naniar)
#used for data imputation
library(VIM)
ckd.data <-read.csv('ckd_data_converted.csv')
vis_miss(ckd.data, sort_miss = TRUE)
